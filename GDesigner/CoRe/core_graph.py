"""
CoRe Framework v4.1: Main Graph Implementation
ÂÆåÊï¥ÈõÜÊàêÔºöRetrieve(Reranker) -> Execute -> Store(List) -> Route(LLM)
"""

import sys
import os

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

import asyncio
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from pathlib import Path
import time

from GDesigner.graph.graph import Graph
from GDesigner.agents.agent_registry import AgentRegistry
from GDesigner.llm.llm_registry import LLMRegistry
import weave


@dataclass
class CoReResult:
    """CoReÊâßË°åÁªìÊûú"""
    final_answer: str
    execution_trace: List[Dict]
    routing_decisions: List[Dict]
    belief_updates: List[Any]
    total_time: float
    total_cost_tokens: int
    success: bool


class CoReGraph:
    """
    Cognitive Relay Graph v4.1 - ‰∏ªÁºñÊéíÂô®

    Ê†∏ÂøÉÊµÅÁ®ãÔºö
    Step 0: ÂÜ∑ÂêØÂä® (Reranker)
    Âæ™ÁéØ (max_routingÊ¨°):
        Step 1: Retrieve (Reranker) - RAGÊ£ÄÁ¥¢ÂéÜÂè≤
        Step 2: Execute - AgentÊâßË°å
        Step 3: Store - Â≠òÂÇ®Âà∞ÂéÜÂè≤ÂàóË°®
        Step 4: Post-hoc Route (LLM) - ÂÜ≥Á≠ñ‰∏ã‰∏ÄÊ£í + ÁîüÊàêInsight
    """

    def __init__(
            self,
            domain: str,
            llm_name: str,
            available_roles: List[str],
            decision_method: str = "FinalRefer",
            max_routing: int = 10,
            registry_save_path: Optional[Path] = None,
            reranker_model: str = "BAAI/bge-reranker-v2-m3",
            rag_top_k: int = 3
    ):
        """ÂàùÂßãÂåñCoRe Graph"""

        # ÂØºÂÖ•Êú¨Âú∞Ê®°Âùó
        from mind_registry import MindRegistry, AgentProfile
        from unified_ranker import UnifiedRanker
        from belief_evolver import BeliefEvolver, InteractionTrace

        self.domain = domain
        self.llm_name = llm_name
        self.available_roles = available_roles
        self.max_routing = max_routing
        self.rag_top_k = rag_top_k

        # ÂàùÂßãÂåñLLM
        self.llm = LLMRegistry.get(llm_name)

        # **ÂÖ≥ÈîÆ‰øÆÊîπ1**: ÂàùÂßãÂåñMind Registry (Âéª‰∏≠ÂøÉÂåñ‰∫íËÆ§)
        self.mind_registry = MindRegistry(save_path=registry_save_path)
        self._initialize_agent_profiles()

        # **ÂÖ≥ÈîÆ‰øÆÊîπ2**: ÂàùÂßãÂåñUnified Ranker (Reranker + LLM)
        self.unified_ranker = UnifiedRanker(
            llm=self.llm,
            reranker_model_name=reranker_model
        )

        # ÂàùÂßãÂåñBelief Evolver
        self.belief_evolver = BeliefEvolver(
            llm=self.llm,
            mind_registry=self.mind_registry
        )

        # ÂàùÂßãÂåñDecision Maker
        self.decision_maker = AgentRegistry.get(
            decision_method,
            domain=domain,
            llm_name=llm_name
        )

        # **ÂÖ≥ÈîÆ‰øÆÊîπ3**: ÊâßË°åÁä∂ÊÄÅ - ‰ΩøÁî®ÂàóË°®Â≠òÂÇ®ÂéÜÂè≤
        self.history_trace = []  # List[str] - Á∫ØÊñáÊú¨ÂéÜÂè≤
        self.current_trace = []  # List[Dict] - ËØ¶ÁªÜÊâßË°åËΩ®Ëøπ
        self.interaction_traces = []

    def _initialize_agent_profiles(self):
        """‰ªédomainÂàùÂßãÂåñAgent profilesÔºåËß¶Âèë‰∫íËÆ§ÂàùÂßãÂåñ"""

        from mind_registry import AgentProfile
        from GDesigner.prompt.prompt_set_registry import PromptSetRegistry

        prompt_set = PromptSetRegistry.get(self.domain)

        for role in self.available_roles:
            try:
                description = prompt_set.get_description(role)

                # ÁÆÄÂåñÁöÑËÉΩÂäõËß£Êûê
                capabilities = []
                if "math" in role.lower():
                    capabilities = ["mathematical reasoning", "problem solving"]
                elif "code" in role.lower():
                    capabilities = ["programming", "implementation"]
                elif "analyst" in role.lower():
                    capabilities = ["analysis", "planning"]

                profile = AgentProfile(
                    agent_id=f"{role.lower().replace(' ', '_')}",
                    role=role,
                    capabilities=capabilities,
                    specializations=[role],
                    limitations=[],
                    description=description
                )

                # **ÂÖ≥ÈîÆ**: register_agent‰ºöËá™Âä®Ëß¶Âèë‰∫íËÆ§ÂàùÂßãÂåñ
                self.mind_registry.register_agent(profile)

            except Exception as e:
                print(f"Warning: Could not register profile for {role}: {e}")

    @weave.op()
    async def run_cognitive_relay(
            self,
            input_dict: Dict[str, str],
            temperature: float = 1.0,
            training: bool = False
    ) -> CoReResult:
        """
        ‰∏ªÊâßË°åÂæ™ÁéØ - Cognitive Relay
        """

        start_time = time.time()
        task = input_dict['task']

        # ÈáçÁΩÆÁä∂ÊÄÅ
        self.history_trace = []  # Á∫ØÊñáÊú¨ÂéÜÂè≤
        self.current_trace = []  # ËØ¶ÁªÜËΩ®Ëøπ
        self.interaction_traces = []
        routing_decisions = []
        total_tokens = 0

        print(f"\n{'=' * 60}")
        print(f"CoRe v4.1: Starting Cognitive Relay")
        print(f"Task: {task[:100]}...")
        print(f"{'=' * 60}\n")

        # **Step 0: ÂÜ∑ÂêØÂä® (Reranker)**
        print("=== Step 0: Cold Start (Reranker) ===")
        profiles = {
            agent_id: self.mind_registry.get_agent_profile(agent_id).to_text()
            for agent_id in [role.lower().replace(' ', '_') for role in self.available_roles]
        }

        current_agent = await self.unified_ranker.cold_start(task, profiles)
        print(f"Cold Start Selected: {current_agent}\n")

        current_output = None
        insight_instruction = None

        # **‰∏ªÂæ™ÁéØ**
        for step in range(self.max_routing):
            print(f"\n--- Step {step + 1}/{self.max_routing} ---")

            # **Step 1: Retrieve (Reranker) - RAGÊ£ÄÁ¥¢**
            print("Step 1: RAG Retrieval (Reranker)")
            retrieved_context = self.unified_ranker.retrieve(
                task=task,
                history_list=self.history_trace,
                top_k=self.rag_top_k
            )
            if retrieved_context:
                print(f"Retrieved {len(retrieved_context.split('---'))} items from history")

            # **Step 2: Execute - AgentÊâßË°å**
            print(f"Step 2: Executing {current_agent}...")
            agent = await self._get_agent_instance(current_agent)

            # ÂáÜÂ§áËæìÂÖ•ÔºöTask + RAG Context + Insight
            agent_input = input_dict.copy()
            agent_input['retrieved_history'] = retrieved_context
            if insight_instruction:
                agent_input['insight'] = insight_instruction

            agent_output = await self._execute_agent(agent, agent_input)
            print(f"Output preview: {agent_output[:100]}...")

            # **Step 3: Store - Â≠òÂÖ•ÂéÜÂè≤ÂàóË°®**
            self.history_trace.append(agent_output)

            # ËÆ∞ÂΩïtrace
            self.current_trace.append({
                'step': step + 1,
                'agent': current_agent,
                'output': agent_output,
                'retrieved_context': retrieved_context,
                'insight': insight_instruction
            })

            # **Step 4: Post-hoc Route (LLM) - ÂÜ≥Á≠ñ‰∏ã‰∏ÄÊ£í**
            print("Step 4: Post-hoc Routing (LLM)...")

            # Ëé∑ÂèñÂÄôÈÄâAgent
            candidate_agents = [
                role.lower().replace(' ', '_')
                for role in self.available_roles
                if role.lower().replace(' ', '_') != current_agent
            ]
            candidate_agents.append(self.decision_maker.id)

            # Ëé∑ÂèñÂΩìÂâçAgentÁöÑÁßÅÊúâ‰∏ä‰∏ãÊñá
            context = self.mind_registry.get_context_for_routing(
                current_agent=current_agent,
                candidate_agents=candidate_agents,
                task_description=task
            )

            # LLMË∑ØÁî±ÂÜ≥Á≠ñ
            routing_decision = await self.unified_ranker.route_llm(
                task=task,
                current_output=agent_output,
                current_agent_id=current_agent,
                candidate_agents=candidate_agents,
                context_from_registry=context
            )

            print(f"Selected: {routing_decision.selected_agent}")
            print(f"Insight: {routing_decision.insight_instruction}")
            print(f"Confidence: {routing_decision.confidence:.2f}")

            routing_decisions.append({
                'step': step + 1,
                'selected': routing_decision.selected_agent,
                'reasoning': routing_decision.reasoning,
                'insight': routing_decision.insight_instruction,
                'confidence': routing_decision.confidence
            })

            total_tokens += routing_decision.cost_tokens

            # **Ê£ÄÊü•ÊòØÂê¶ÈÄâÊã©‰∫ÜDecision Maker (ÁªàÊ≠¢Êù°‰ª∂)**
            if routing_decision.selected_agent == self.decision_maker.id:
                print("\nüéØ Decision maker selected - reaching consensus...")

                final_output = await self._execute_decision_maker(
                    input_dict, self.history_trace
                )

                execution_time = time.time() - start_time

                print(f"\n{'=' * 60}")
                print(f"CoRe v4.1: Relay Complete")
                print(f"Total Steps: {step + 1}")
                print(f"Time: {execution_time:.2f}s")
                print(f"Tokens: {total_tokens}")
                print(f"{'=' * 60}\n")

                # **‰øùÂ≠òËÆ∞ÂøÜÂíåËøõÂåñ**
                self.mind_registry.save()

                result = CoReResult(
                    final_answer=final_output,
                    execution_trace=self.current_trace,
                    routing_decisions=routing_decisions,
                    belief_updates=[],
                    total_time=execution_time,
                    total_cost_tokens=total_tokens,
                    success=True
                )

                return result

            # Êõ¥Êñ∞Áä∂ÊÄÅÁî®‰∫é‰∏ã‰∏ÄËΩÆ
            current_agent = routing_decision.selected_agent
            current_output = agent_output
            insight_instruction = routing_decision.insight_instruction

        # ËææÂà∞ÊúÄÂ§ßÊ≠•Êï∞
        print("\n‚ö†Ô∏è  Max routing steps reached - forcing decision...")
        final_output = await self._execute_decision_maker(input_dict, self.history_trace)

        result = CoReResult(
            final_answer=final_output,
            execution_trace=self.current_trace,
            routing_decisions=routing_decisions,
            belief_updates=[],
            total_time=time.time() - start_time,
            total_cost_tokens=total_tokens,
            success=False
        )

        return result

    async def _get_agent_instance(self, agent_id: str):
        """Ëé∑ÂèñÊàñÂàõÂª∫AgentÂÆû‰æã"""

        # Êò†Â∞Ñagent_idÂà∞role
        role = agent_id.replace('_', ' ').title()

        for available_role in self.available_roles:
            if available_role.lower().replace(' ', '_') == agent_id:
                role = available_role
                break

        # Ê†πÊçÆdomainÁ°ÆÂÆöAgentÁ±ªÂûã
        if self.domain == "gsm8k":
            agent_class = "MathSolver"
        elif self.domain == "humaneval":
            agent_class = "CodeWriting"
        elif self.domain == "mmlu":
            agent_class = "CoReAnalyzeAgent"
        else:
            agent_class = "MathSolver"

        agent = AgentRegistry.get(
            agent_class,
            domain=self.domain,
            llm_name=self.llm_name,
            role=role
        )

        return agent

    @weave.op()
    async def _execute_agent(self, agent, input_dict: Dict) -> str:
        """ÊâßË°åAgentÂπ∂ËøîÂõûËæìÂá∫"""

        await agent.async_execute(input_dict)

        if agent.outputs:
            return agent.outputs[-1]
        return "No output generated"

    async def _execute_decision_maker(
            self,
            input_dict: Dict,
            history: List[str]
    ) -> str:
        """ÊâßË°åDecision Maker"""

        # ÊûÑÂª∫‰∏ä‰∏ãÊñá
        spatial_info = {}
        for i, output in enumerate(history[-5:]):  # ÊúÄËøë5‰∏™ËæìÂá∫
            spatial_info[f"agent_{i}"] = {
                'role': f"step_{i}",
                'output': output
            }

        await self.decision_maker.async_execute(input_dict)

        if self.decision_maker.outputs:
            return self.decision_maker.outputs[-1]
        return "No decision produced"

    def get_statistics(self) -> Dict:
        """Ëé∑ÂèñÊâßË°åÁªüËÆ°"""

        ranker_stats = self.unified_ranker.get_statistics()
        evolution_stats = self.belief_evolver.get_evolution_summary()

        return {
            'routing': ranker_stats,
            'evolution': evolution_stats,
            'total_beliefs': len(self.mind_registry.beliefs),
            'registered_agents': len(self.mind_registry.profiles)
        }


# ‰ΩøÁî®Á§∫‰æã
if __name__ == "__main__":
    weave.init(
        project_name='vito_chan/G-Designer',
    )


    async def test_core():
        core = CoReGraph(
            domain="mmlu",
            llm_name="Qwen/Qwen3-4B-Instruct-2507",
            available_roles=[
                'Knowlegable Expert',
                'Critic',
                'Mathematician',
                'Psychologist',
                'Historian',
            ],
            max_routing=5
        )

        input_dict = {
            "task": "Solve the equation 2x^2 + 5x - 3 = 0"
        }

        result = await core.run_cognitive_relay(input_dict)

        print("\n" + "=" * 60)
        print("FINAL RESULT")
        print("=" * 60)
        print(f"Answer: {result.final_answer}")
        print(f"Success: {result.success}")
        print(f"Steps: {len(result.execution_trace)}")
        print(f"Total Time: {result.total_time:.2f}s")
        print(f"Total Tokens: {result.total_cost_tokens}")

        print("\n" + "=" * 60)
        print("STATISTICS")
        print("=" * 60)
        stats = core.get_statistics()
        print(f"Cold Starts: {stats['routing']['cold_start_count']}")
        print(f"RAG Retrievals: {stats['routing']['rag_retrieval_count']}")
        print(f"LLM Routes: {stats['routing']['post_hoc_route_count']}")


    asyncio.run(test_core())
